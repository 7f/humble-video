/* ----------------------------------------------------------------------------
 * This file was automatically generated by SWIG (http://www.swig.org).
 * Version 2.0.0
 *
 * Do not make changes to this file unless you know what you are doing--modify
 * the SWIG interface file instead.
 * ----------------------------------------------------------------------------- */

package io.humble.video;
import io.humble.ferry.*;
/**
 * A set of raw (decoded) samples, plus a timestamp for when to play 
 * those  
 * samples relative to other items in a given {@link Container}.  
 * The timestamp value in decoded data is always in Microseonds.  
 */
public class AudioSamples extends MediaRawData {
  // JNIHelper.swg: Start generated code
  // >>>>>>>>>>>>>>>>>>>>>>>>>>>
  /**
   * This method is only here to use some references and remove
   * a Eclipse compiler warning.
   */
  @SuppressWarnings("unused")
  private void noop()
  {
    IBuffer.make(null, 1);
  }
   
  private volatile long swigCPtr;

  /**
   * Internal Only.
   */
  protected AudioSamples(long cPtr, boolean cMemoryOwn) {
    super(VideoJNI.SWIGAudioSamplesUpcast(cPtr), cMemoryOwn);
    swigCPtr = cPtr;
  }
  
  /**
   * Internal Only.
   */
  protected AudioSamples(long cPtr, boolean cMemoryOwn,
      java.util.concurrent.atomic.AtomicLong ref)
  {
    super(VideoJNI.SWIGAudioSamplesUpcast(cPtr),
     cMemoryOwn, ref);
    swigCPtr = cPtr;
  }
    
  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that obj is proxying for.
   *   
   * @param obj The java proxy object for a native object.
   * @return The raw pointer obj is proxying for.
   */
  protected static long getCPtr(AudioSamples obj) {
    if (obj == null) return 0;
    return obj.getMyCPtr();
  }

  /**
   * Internal Only.  Not part of public API.
   *
   * Get the raw value of the native object that we're proxying for.
   *   
   * @return The raw pointer we're proxying for.
   */  
  protected long getMyCPtr() {
    if (swigCPtr == 0) throw new IllegalStateException("underlying native object already deleted");
    return swigCPtr;
  }
  
  /**
   * Create a new AudioSamples object that is actually referring to the
   * exact same underlying native object.
   *
   * @return the new Java object.
   */
  @Override
  public AudioSamples copyReference() {
    if (swigCPtr == 0)
      return null;
    else
      return new AudioSamples(swigCPtr, swigCMemOwn, getJavaRefCount());
  }

  /**
   * Compares two values, returning true if the underlying objects in native code are the same object.
   *
   * That means you can have two different Java objects, but when you do a comparison, you'll find out
   * they are the EXACT same object.
   *
   * @return True if the underlying native object is the same.  False otherwise.
   */
  public boolean equals(Object obj) {
    boolean equal = false;
    if (obj instanceof AudioSamples)
      equal = (((AudioSamples)obj).swigCPtr == this.swigCPtr);
    return equal;
  }
  
  /**
   * Get a hashable value for this object.
   *
   * @return the hashable value.
   */
  public int hashCode() {
     return (int)swigCPtr;
  }
  
  // <<<<<<<<<<<<<<<<<<<<<<<<<<<
  // JNIHelper.swg: End generated code
  

  /**
   * info about this packet
   * @return information about this packet
   */
   
  @Override
  public String toString()
  {
    StringBuilder result = new StringBuilder();
    
    result.append(this.getClass().getName()+"@"+hashCode()+"[");
    result.append("sample rate:"+getSampleRate()+";");
    result.append("channels:"+getChannels()+";");
    result.append("format:"+getFormat()+";");
    result.append("time stamp:"+getTimeStamp()+";");
    result.append("complete:"+isComplete()+";");
    result.append("num samples:"+getNumSamples()+";");
    result.append("size:"+getSize()+";");
    result.append("key:"+isKey()+";");
    Rational timeBase = Rational.make(1,(int)Global.DEFAULT_PTS_PER_SECOND);
    result.append("time base:"+timeBase+";");
    if (timeBase != null) timeBase.delete();
    result.append("]");
    return result.toString();
  }


/**
 * Find the sample rate of the samples in this audio buffer.  
 * @return	The Sampling Rate of the samples in this buffer (e.g. 22050). 
 *		  
 */
  public int getSampleRate() {
    return VideoJNI.AudioSamples_getSampleRate(swigCPtr, this);
  }

/**
 * Return the number of channels of the samples in this buffer. For 
 * example,  
 * 1 is mono, 2 is stereo.  
 * @return	The number of channels.  
 */
  public int getChannels() {
    return VideoJNI.AudioSamples_getChannels(swigCPtr, this);
  }

/**
 * Find out the number of bytes a single sample (one channel) of audio 
 *  
 * in this object takes up.  
 * @return	Number of bytes in a raw sample (per channel)  
 */
  public int getSampleSize() {
    return VideoJNI.AudioSamples_getSampleSize(swigCPtr, this);
  }

/**
 * Find the Format of the samples in this buffer. Right now  
 * only FMT_S16 is supported.  
 * @return	The format of the samples.  
 */
  public AudioSamples.Format getFormat() {
    return AudioSamples.Format.swigToEnum(VideoJNI.AudioSamples_getFormat(swigCPtr, this));
  }

/**
 * Is the audio is a planar format (as opposed to packed).  
 */
  public boolean isPlanar() {
    return VideoJNI.AudioSamples_isPlanar(swigCPtr, this);
  }

/**
 * Get the number of samples in this video.  
 *  
 * audio in this buffer, there are 25 samples. If you have  
 * 100 bytes of mono (1-channel) 16-bit audio in this buffer, you  
 * have 50 samples.  
 * @return	The number of samples.  
 */
  public int getNumSamples() {
    return VideoJNI.AudioSamples_getNumSamples(swigCPtr, this);
  }

/**
 * @return	Maximum number of bytes that can be put in  
 * this buffer. To get the number of samples you can  
 * put in this AudioSamples instance, do the following  
 * num_samples = getMaxBufferSize() (getSampleSize())  
 */
  public int getMaxBufferSize() {
    return VideoJNI.AudioSamples_getMaxBufferSize(swigCPtr, this);
  }

/**
 * @return	Maximum number of samples this buffer can hold.  
 */
  public int getMaxSamples() {
    return VideoJNI.AudioSamples_getMaxSamples(swigCPtr, this);
  }

/**
 * What is the Presentation Time Stamp of this set of audio samples. 
 *  
 * @return	the presentation time stamp (pts)  
 */
  public long getPts() {
    return VideoJNI.AudioSamples_getPts(swigCPtr, this);
  }

/**
 * Set the Presentation Time Stamp for this set of samples.  
 * @param	aValue the new value  
 */
  public void setPts(long aValue) {
    VideoJNI.AudioSamples_setPts(swigCPtr, this, aValue);
  }

/**
 * What would be the next Presentation Time Stamp after all the  
 * samples in this buffer were played?  
 * @return	the next presentation time stamp (pts)  
 */
  public long getNextPts() {
    return VideoJNI.AudioSamples_getNextPts(swigCPtr, this);
  }

/**
 * Call this if you modify the samples and are now done. This  
 * updates the pertinent information in the structure.  
 * @param	complete Is this set of samples complete?  
 * @param	numSamples Number of samples in this update (note that  
 * 4 shorts of 16-bit audio in stereo is actually 1 sample).  
 * @param	sampleRate The sample rate (in Hz) of this set of samples. 
 *		  
 * @param	channels The number of channels in this set of samples.  
 * @param	format The sample-format of this set of samples.  
 * @param	pts The presentation time stamp of the starting sample in 
 *		 this buffer.  
 * Caller must ensure pts is in units of 1/1,000,000 of a second  
 */
  public void setComplete(boolean complete, int numSamples, int sampleRate, int channels, AudioSamples.Format format, long pts) {
    VideoJNI.AudioSamples_setComplete(swigCPtr, this, complete, numSamples, sampleRate, channels, format.swigValue(), pts);
  }

/**
 * Converts a number of samples at a given sampleRate into  
 * Microseconds.  
 * @param	samples Number of samples.  
 * @param	sampleRate sample rate that those samples are recorded at. 
 *		  
 * @return	number of microseconds it would take to play that audio. 
 *		  
 */
  public static long samplesToDefaultPts(long samples, int sampleRate) {
    return VideoJNI.AudioSamples_samplesToDefaultPts(samples, sampleRate);
  }

/**
 * Converts a duration in microseconds into  
 * a number of samples, assuming a given sampleRate.  
 * @param	duration The duration in microseconds.  
 * @param	sampleRate sample rate that you want to use.  
 * @return	The number of samples it would take (at the given sampleRate) 
 *		 to take duration microseconds to play.  
 */
  public static long defaultPtsToSamples(long duration, int sampleRate) {
    return VideoJNI.AudioSamples_defaultPtsToSamples(duration, sampleRate);
  }

/**
 * Creates an {@link AudioSamples} object by wrapping an  
 * {@link io.humble.ferry.IBuffer object}.  
 * @param	buffer the buffer to wrap  
 * @param	channels the number of channels of audio you will put it the 
 *		 buffer  
 * @param	format the audio sample format  
 * @return	a new {@link AudioSamples} object, or null on error.  
 */
  public static AudioSamples make(IBuffer buffer, int numSamples, int channels, AudioSamples.Format format) {
    long cPtr = VideoJNI.AudioSamples_make__SWIG_0(IBuffer.getCPtr(buffer), buffer, numSamples, channels, format.swigValue());
    return (cPtr == 0) ? null : new AudioSamples(cPtr, false);
  }

/**
 * Get a new audio samples buffer.  
 * <p>  
 * Note that any buffers this objects needs will be  
 * lazily allocated (i.e. we won't actually grab all  
 * the memory until we need it).  
 * </p>  
 * @param	numSamples The minimum number of samples you're  
 * going to want to put in this buffer. We may (and probably  
 * will) return a larger buffer, but you cannot assume that.  
 * @param	numChannels The number of channels in the audio you'll  
 * want to put in this buffer.  
 * @param	format The format of this buffer  
 * @return	A new object, or null if we can't allocate one.  
 */
  public static AudioSamples make(int numSamples, long numChannels, AudioSamples.Format format) {
    long cPtr = VideoJNI.AudioSamples_make__SWIG_1(numSamples, numChannels, format.swigValue());
    return (cPtr == 0) ? null : new AudioSamples(cPtr, false);
  }

  public enum Format {
  /**
   * The format we use to represent audio. Today
   * only FMT_S16 (signed integer 16-bit audio) is supported.
   * No format
   */
    SAMPLE_FMT_NONE(VideoJNI.AudioSamples_SAMPLE_FMT_NONE_get()),
  /**
   * unsigned 8 bits
   */
    SAMPLE_FMT_U8(VideoJNI.AudioSamples_SAMPLE_FMT_U8_get()),
  /**
   * signed 16 bits
   */
    SAMPLE_FMT_S16(VideoJNI.AudioSamples_SAMPLE_FMT_S16_get()),
  /**
   * signed 32 bits
   */
    SAMPLE_FMT_S32(VideoJNI.AudioSamples_SAMPLE_FMT_S32_get()),
  /**
   * float
   */
    SAMPLE_FMT_FLT(VideoJNI.AudioSamples_SAMPLE_FMT_FLT_get()),
  /**
   * double
   */
    SAMPLE_FMT_DBL(VideoJNI.AudioSamples_SAMPLE_FMT_DBL_get()),
  /**
   * unsigned 8 bits, planar
   */
    SAMPLE_FMT_U8P(VideoJNI.AudioSamples_SAMPLE_FMT_U8P_get()),
  /**
   * signed 16 bits, planar
   */
    SAMPLE_FMT_S16P(VideoJNI.AudioSamples_SAMPLE_FMT_S16P_get()),
  /**
   * signed 32 bits, planar
   */
    SAMPLE_FMT_S32P(VideoJNI.AudioSamples_SAMPLE_FMT_S32P_get()),
  /**
   * float, planar
   */
    SAMPLE_FMT_FLTP(VideoJNI.AudioSamples_SAMPLE_FMT_FLTP_get()),
  /**
   * double, planar
   */
    SAMPLE_FMT_DBLP(VideoJNI.AudioSamples_SAMPLE_FMT_DBLP_get());

    public final int swigValue() {
      return swigValue;
    }

    public static Format swigToEnum(int swigValue) {
      Format[] swigValues = Format.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (Format swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + Format.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private Format() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private Format(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private Format(Format swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

  public enum ChannelLayout {
    CH_FRONT_LEFT(VideoJNI.AudioSamples_CH_FRONT_LEFT_get()),
    CH_FRONT_RIGHT(VideoJNI.AudioSamples_CH_FRONT_RIGHT_get()),
    CH_FRONT_CENTER(VideoJNI.AudioSamples_CH_FRONT_CENTER_get()),
    CH_LOW_FREQUENCY(VideoJNI.AudioSamples_CH_LOW_FREQUENCY_get()),
    CH_BACK_LEFT(VideoJNI.AudioSamples_CH_BACK_LEFT_get()),
    CH_BACK_RIGHT(VideoJNI.AudioSamples_CH_BACK_RIGHT_get()),
    CH_FRONT_LEFT_OF_CENTER(VideoJNI.AudioSamples_CH_FRONT_LEFT_OF_CENTER_get()),
    CH_FRONT_RIGHT_OF_CENTER(VideoJNI.AudioSamples_CH_FRONT_RIGHT_OF_CENTER_get()),
    CH_BACK_CENTER(VideoJNI.AudioSamples_CH_BACK_CENTER_get()),
    CH_SIDE_LEFT(VideoJNI.AudioSamples_CH_SIDE_LEFT_get()),
    CH_SIDE_RIGHT(VideoJNI.AudioSamples_CH_SIDE_RIGHT_get()),
    CH_TOP_CENTER(VideoJNI.AudioSamples_CH_TOP_CENTER_get()),
    CH_TOP_FRONT_LEFT(VideoJNI.AudioSamples_CH_TOP_FRONT_LEFT_get()),
    CH_TOP_FRONT_CENTER(VideoJNI.AudioSamples_CH_TOP_FRONT_CENTER_get()),
    CH_TOP_FRONT_RIGHT(VideoJNI.AudioSamples_CH_TOP_FRONT_RIGHT_get()),
    CH_TOP_BACK_LEFT(VideoJNI.AudioSamples_CH_TOP_BACK_LEFT_get()),
    CH_TOP_BACK_CENTER(VideoJNI.AudioSamples_CH_TOP_BACK_CENTER_get()),
    CH_TOP_BACK_RIGHT(VideoJNI.AudioSamples_CH_TOP_BACK_RIGHT_get()),
    CH_STEREO_LEFT(VideoJNI.AudioSamples_CH_STEREO_LEFT_get()),
    CH_STEREO_RIGHT(VideoJNI.AudioSamples_CH_STEREO_RIGHT_get()),
    CH_WIDE_LEFT(VideoJNI.AudioSamples_CH_WIDE_LEFT_get()),
    CH_WIDE_RIGHT(VideoJNI.AudioSamples_CH_WIDE_RIGHT_get()),
    CH_SURROUND_DIRECT_LEFT(VideoJNI.AudioSamples_CH_SURROUND_DIRECT_LEFT_get()),
    CH_SURROUND_DIRECT_RIGHT(VideoJNI.AudioSamples_CH_SURROUND_DIRECT_RIGHT_get()),
    CH_LOW_FREQUENCY_2(VideoJNI.AudioSamples_CH_LOW_FREQUENCY_2_get()),
    CH_LAYOUT_MONO(VideoJNI.AudioSamples_CH_LAYOUT_MONO_get()),
    CH_LAYOUT_STEREO(VideoJNI.AudioSamples_CH_LAYOUT_STEREO_get()),
    CH_LAYOUT_2POINT1(VideoJNI.AudioSamples_CH_LAYOUT_2POINT1_get()),
    CH_LAYOUT_2_1(VideoJNI.AudioSamples_CH_LAYOUT_2_1_get()),
    CH_LAYOUT_SURROUND(VideoJNI.AudioSamples_CH_LAYOUT_SURROUND_get()),
    CH_LAYOUT_3POINT1(VideoJNI.AudioSamples_CH_LAYOUT_3POINT1_get()),
    CH_LAYOUT_4POINT0(VideoJNI.AudioSamples_CH_LAYOUT_4POINT0_get()),
    CH_LAYOUT_4POINT1(VideoJNI.AudioSamples_CH_LAYOUT_4POINT1_get()),
    CH_LAYOUT_2_2(VideoJNI.AudioSamples_CH_LAYOUT_2_2_get()),
    CH_LAYOUT_QUAD(VideoJNI.AudioSamples_CH_LAYOUT_QUAD_get()),
    CH_LAYOUT_5POINT0(VideoJNI.AudioSamples_CH_LAYOUT_5POINT0_get()),
    CH_LAYOUT_5POINT1(VideoJNI.AudioSamples_CH_LAYOUT_5POINT1_get()),
    CH_LAYOUT_5POINT0_BACK(VideoJNI.AudioSamples_CH_LAYOUT_5POINT0_BACK_get()),
    CH_LAYOUT_5POINT1_BACK(VideoJNI.AudioSamples_CH_LAYOUT_5POINT1_BACK_get()),
    CH_LAYOUT_6POINT0(VideoJNI.AudioSamples_CH_LAYOUT_6POINT0_get()),
    CH_LAYOUT_6POINT0_FRONT(VideoJNI.AudioSamples_CH_LAYOUT_6POINT0_FRONT_get()),
    CH_LAYOUT_HEXAGONAL(VideoJNI.AudioSamples_CH_LAYOUT_HEXAGONAL_get()),
    CH_LAYOUT_6POINT1(VideoJNI.AudioSamples_CH_LAYOUT_6POINT1_get()),
    CH_LAYOUT_6POINT1_BACK(VideoJNI.AudioSamples_CH_LAYOUT_6POINT1_BACK_get()),
    CH_LAYOUT_6POINT1_FRONT(VideoJNI.AudioSamples_CH_LAYOUT_6POINT1_FRONT_get()),
    CH_LAYOUT_7POINT0(VideoJNI.AudioSamples_CH_LAYOUT_7POINT0_get()),
    CH_LAYOUT_7POINT0_FRONT(VideoJNI.AudioSamples_CH_LAYOUT_7POINT0_FRONT_get()),
    CH_LAYOUT_7POINT1(VideoJNI.AudioSamples_CH_LAYOUT_7POINT1_get()),
    CH_LAYOUT_7POINT1_WIDE(VideoJNI.AudioSamples_CH_LAYOUT_7POINT1_WIDE_get()),
    CH_LAYOUT_7POINT1_WIDE_BACK(VideoJNI.AudioSamples_CH_LAYOUT_7POINT1_WIDE_BACK_get()),
    CH_LAYOUT_OCTAGONAL(VideoJNI.AudioSamples_CH_LAYOUT_OCTAGONAL_get()),
    CH_LAYOUT_STEREO_DOWNMIX(VideoJNI.AudioSamples_CH_LAYOUT_STEREO_DOWNMIX_get());

    public final int swigValue() {
      return swigValue;
    }

    public static ChannelLayout swigToEnum(int swigValue) {
      ChannelLayout[] swigValues = ChannelLayout.class.getEnumConstants();
      if (swigValue < swigValues.length && swigValue >= 0 && swigValues[swigValue].swigValue == swigValue)
        return swigValues[swigValue];
      for (ChannelLayout swigEnum : swigValues)
        if (swigEnum.swigValue == swigValue)
          return swigEnum;
      throw new IllegalArgumentException("No enum " + ChannelLayout.class + " with value " + swigValue);
    }

    @SuppressWarnings("unused")
    private ChannelLayout() {
      this.swigValue = SwigNext.next++;
    }

    @SuppressWarnings("unused")
    private ChannelLayout(int swigValue) {
      this.swigValue = swigValue;
      SwigNext.next = swigValue+1;
    }

    @SuppressWarnings("unused")
    private ChannelLayout(ChannelLayout swigEnum) {
      this.swigValue = swigEnum.swigValue;
      SwigNext.next = this.swigValue+1;
    }

    private final int swigValue;

    private static class SwigNext {
      private static int next = 0;
    }
  }

}
